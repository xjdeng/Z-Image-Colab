{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Credit:\n",
        "[Z-Image Github](https://github.com/Tongyi-MAI/Z-Image) <br>\n",
        "Colab Code: [camenduru](https://github.com/camenduru/Z-Image-jupyter)\n"
      ],
      "metadata": {
        "id": "PROsUqH9x77h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5NUBaPey9U2G"
      },
      "outputs": [],
      "source": [
        "#@title Install Z-Image-Turbo\n",
        "#ComfyUI Installation\n",
        "%cd /content/\n",
        "!git clone https://github.com/comfyanonymous/ComfyUI\n",
        "\n",
        "%cd /content/ComfyUI\n",
        "!wget https://raw.githubusercontent.com/NeuralFalconYT/Z-Image-Colab/refs/heads/main/app.py\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "#Model Download\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/T5B/Z-Image-Turbo-FP8/resolve/main/z-image-turbo-fp8-e4m3fn.safetensors -d /content/ComfyUI/models/diffusion_models -o z-image-turbo-fp8-e4m3fn.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/text_encoders/qwen_3_4b.safetensors -d /content/ComfyUI/models/clip -o qwen_3_4b.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/Comfy-Org/z_image_turbo/resolve/main/split_files/vae/ae.safetensors -d /content/ComfyUI/models/vae -o ae.safetensors\n",
        "\n",
        "#Clear Terminal\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"\\033[92mZ-Image-Turbo Installation successful\\033[0m\")\n",
        "import os\n",
        "\n",
        "paths = [\n",
        "    \"/content/ComfyUI/models/diffusion_models/z-image-turbo-fp8-e4m3fn.safetensors\",\n",
        "    \"/content/ComfyUI/models/clip/qwen_3_4b.safetensors\",\n",
        "    \"/content/ComfyUI/models/vae/ae.safetensors\",\n",
        "]\n",
        "\n",
        "for p in paths:\n",
        "    if not os.path.exists(p):\n",
        "        print(f\"\\033[91mMISSING (possibly HuggingFace blocked download): {p}\\033[0m\")\n",
        "\n",
        "#@title Keep Alive for Mobile Users\n",
        "from IPython.display import Audio,display\n",
        "import numpy as np\n",
        "display(Audio(np.array([0] * 2 * 3600 * 3000, dtype=np.int8), normalize=False, rate=3000, autoplay=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gradio app (Might crash on low GPU memory)\n",
        "%cd /content/ComfyUI\n",
        "!python app.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PGubKwVUeBBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fEUmz06LmWJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run from colab cell"
      ],
      "metadata": {
        "id": "J9Xllo8CmWuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utils Code\n",
        "%cd /content/ComfyUI\n",
        "\n",
        "import os, random, time\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import re, uuid\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "\n",
        "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
        "CLIPLoader = NODE_CLASS_MAPPINGS[\"CLIPLoader\"]()\n",
        "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
        "CLIPTextEncode = NODE_CLASS_MAPPINGS[\"CLIPTextEncode\"]()\n",
        "KSampler = NODE_CLASS_MAPPINGS[\"KSampler\"]()\n",
        "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
        "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
        "\n",
        "with torch.inference_mode():\n",
        "    unet = UNETLoader.load_unet(\"z-image-turbo-fp8-e4m3fn.safetensors\", \"fp8_e4m3fn_fast\")[0]\n",
        "    clip = CLIPLoader.load_clip(\"qwen_3_4b.safetensors\", type=\"lumina2\")[0]\n",
        "    vae = VAELoader.load_vae(\"ae.safetensors\")[0]\n",
        "\n",
        "save_dir=\"./results\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "def get_save_path(prompt):\n",
        "  save_dir = \"./results\"\n",
        "  safe_prompt = re.sub(r'[^a-zA-Z0-9_-]', '_', prompt)[:25]\n",
        "  uid = uuid.uuid4().hex[:6]\n",
        "  filename = f\"{safe_prompt}_{uid}.png\"\n",
        "  path = os.path.join(save_dir, filename)\n",
        "  return path\n",
        "\n",
        "@torch.inference_mode()\n",
        "def generate(input):\n",
        "    values = input[\"input\"]\n",
        "    positive_prompt = values['positive_prompt']\n",
        "    negative_prompt = values['negative_prompt']\n",
        "    seed = values['seed'] # 0\n",
        "    steps = values['steps'] # 9\n",
        "    cfg = values['cfg'] # 1.0\n",
        "    sampler_name = values['sampler_name'] # euler\n",
        "    scheduler = values['scheduler'] # simple\n",
        "    denoise = values['denoise'] # 1.0\n",
        "    width = values['width'] # 1024\n",
        "    height = values['height'] # 1024\n",
        "    batch_size = values['batch_size'] # 1.0\n",
        "\n",
        "    if seed == 0:\n",
        "        random.seed(int(time.time()))\n",
        "        seed = random.randint(0, 18446744073709551615)\n",
        "\n",
        "    positive = CLIPTextEncode.encode(clip, positive_prompt)[0]\n",
        "    negative = CLIPTextEncode.encode(clip, negative_prompt)[0]\n",
        "    latent_image = EmptyLatentImage.generate(width, height, batch_size=batch_size)[0]\n",
        "    samples = KSampler.sample(unet, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)[0]\n",
        "    decoded = VAEDecode.decode(vae, samples)[0].detach()\n",
        "    save_path=get_save_path(positive_prompt)\n",
        "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(save_path)\n",
        "    return save_path,seed"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GpDjqdueK1Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Generation Tip\n",
        "Use ```ChatGPT``` or ```Gemini``` to generate positive and negative prompts based on what you want to create.\n"
      ],
      "metadata": {
        "id": "gX4eu9kknAjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_prompt = 'A photorealistic, ultra detailed, humorous scene on a bustling dutch street market. A tabby cat anthropomorphized, running on two legs while tightly hugging a large, shiny silver fish. The cat has a determined, dramatic facial expression with wide eyes and an open mouth, as if mid-shout. Behind the cat, a shocked fish vendor in an apron is chasing after it, yelling. Fresh fishes are laid out on a market stall to the right, displayed on ice. The background features open stalls, market signs, and a few bystanders reacting in surprise. Dynamic lighting, rich details, cinematic composition, freeze-frame action shot, expressive motion blur, '  # @param {type: \"string\"}\n",
        "negative_prompt = 'low resolution, blurry subject, muddy focus, extreme motion blur, double exposure, ghosting, smearing, pixelated, jpeg artifacts, noise, banding  bad anatomy, deformed cat, extra legs, missing legs, extra tail, broken spine, twisted body, malformed face, misaligned eyes, bad mouth shape, extra limbs on human, fused fingers, broken hands  unnatural pose, stiff movement, floating subjects, wrong perspective, warped proportions, stretched cat, tiny head, giant head  dead fish look, deformed fish, unrealistic fish scales, melted texture, broken highlights, flat metal reflections  poor lighting, flat lighting, blown highlights, crushed shadows, incorrect shadows, inconsistent light direction  bad composition, off-center subject, awkward framing, cut off cat, cut off face, crowded scene, cluttered background, blocking foreground  low realism, cartoon, anime, illustration, painting, CGI look, game graphics, toy-like, plush-like fur  wrong setting, non-Dutch market, incorrect environment, indoor market, modern mall, supermarket aisles  bad emotion, neutral face, blank expression, lifeless eyes, no urgency  text, watermark, logo, captions, frame, borders'  # @param {type: \"string\"}\n",
        "\n",
        "aspect_ratio =\"720x1280 ( 9:16 )\"  # @param [ \"1024x1024 ( 1:1 )\", \"1152x896 ( 9:7 )\", \"896x1152 ( 7:9 )\", \"1152x864 ( 4:3 )\", \"864x1152 ( 3:4 )\", \"1248x832 ( 3:2 )\", \"832x1248 ( 2:3 )\", \"1280x720 ( 16:9 )\", \"720x1280 ( 9:16 )\", \"1344x576 ( 21:9 )\", \"576x1344 ( 9:21 )\"]\n",
        "seed = 0  # @param {type: \"number\"}\n",
        "steps = 9  # @param {type: \"number\"}\n",
        "cfg = 1.0  # @param {type: \"number\"}\n",
        "denoise = 1.0  # @param {type: \"number\"}\n",
        "Download_Image = False  # @param {type: \"boolean\"}\n",
        "\n",
        "batch_size=1\n",
        "sampler_name=\"euler\"\n",
        "scheduler=\"simple\"\n",
        "width,height = [int(x) for x in aspect_ratio.split(\"(\")[0].strip().split(\"x\")]\n",
        "\n",
        "input = {\n",
        "  \"input\": {\n",
        "    \"positive_prompt\": positive_prompt,\n",
        "    \"negative_prompt\": negative_prompt,\n",
        "    \"width\": width,\n",
        "    \"height\": height,\n",
        "    \"batch_size\": batch_size,\n",
        "    \"seed\": seed,\n",
        "    \"steps\": steps,\n",
        "    \"cfg\": cfg,\n",
        "    \"sampler_name\": sampler_name,\n",
        "    \"scheduler\": scheduler,\n",
        "    \"denoise\": denoise,\n",
        "  }\n",
        "}\n",
        "\n",
        "image_path,seed= generate(input)\n",
        "img = Image.open(image_path)\n",
        "print(f\"\\033[38;2;66;133;244mImage saved at {image_path}\\033[0m\")\n",
        "\n",
        "if Download_Image:\n",
        "  from google.colab import files\n",
        "  files.download(image_path)\n",
        "preview = img.copy()\n",
        "preview.thumbnail((300, 300))\n",
        "from IPython.display import display\n",
        "#colab friendly\n",
        "display(preview)\n",
        "\n",
        "#original image\n",
        "# display(img)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "2B3pFSTKLBAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display Original Image\n",
        "display(img)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XpwpQJ9Ls9Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Image\n",
        "from google.colab import files\n",
        "files.download(image_path)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kttl8SAJkUkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}